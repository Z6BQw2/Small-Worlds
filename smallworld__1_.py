# -*- coding: utf-8 -*-
"""smallworld.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S56GrjfhhuGO_Qnb6Camf-tPNabOZlD1
"""

import pandas as pd

df = pd.read_json('baba.jsonl', lines=True, orient='records')

pd.set_option('display.max_colwidth', None)

pd.set_option('display.max_columns', None)

df['nombre_co_authors'] = df['coauthors'].apply(lambda x: len(x) if isinstance(x, list) else 0)

print(df.size)
print(df.head())

import matplotlib.pyplot as plt
import seaborn as sns

# On utilise votre colonne calculée précédemment
plt.figure(figsize=(10, 6))
sns.histplot(df['nombre_co_authors'], bins=30, kde=True, color='skyblue')

plt.title('Distribution du nombre de co-auteurs (Degree Distribution)')
plt.xlabel('Nombre de co-auteurs')
plt.ylabel("Nombre d'auteurs (Fréquence)")
plt.yscale('log') # ASTUCE : L'échelle log permet de mieux voir la "Long Tail" typique des Small Worlds

plt.show()

import networkx as nx

# Création du graphe vide
G = nx.Graph()

# On boucle sur chaque ligne du DataFrame pour créer les liens
for index, row in df.iterrows():
    auteur_principal = row['author'] # ou le nom de la colonne auteur
    co_auteurs = row['coauthors']

    # Si co_authors est une liste, on crée un lien pour chaque co-auteur
    if isinstance(co_auteurs, list):
        for co_auteur in co_auteurs:
            # On ajoute un lien (edge) entre l'auteur et son co-auteur
            G.add_edge(auteur_principal, co_auteur)

print(f"Nombre de nœuds (auteurs) : {G.number_of_nodes()}")
print(f"Nombre de liens (collaborations) : {G.number_of_edges()}")

degres = dict(G.degree) # Dictionnaire {auteur: nombre_liens}
top_auteurs = sorted(degres, key=degres.get, reverse=True)[:50] # Les 50 plus gros

# 2. On crée un sous-graphe avec juste ces gens-là
sub_G = G.subgraph(top_auteurs)

# 3. On dessine
plt.figure(figsize=(12, 12))
pos = nx.spring_layout(sub_G, k=0.3) # Algorithme de placement (force-directed)

# Les nœuds
nx.draw_networkx_nodes(sub_G, pos, node_size=[v * 10 for v in dict(sub_G.degree).values()], node_color='orange')
# Les liens
nx.draw_networkx_edges(sub_G, pos, alpha=0.3)
# Les noms
nx.draw_networkx_labels(sub_G, pos, font_size=8)

plt.title("Le 'Small World' des 50 plus gros collaborateurs")
plt.axis('off')
plt.show()

import networkx as nx
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import random

# 1. Préparation : On prend la plus grande composante connectée
# (On ne peut pas calculer de chemin si les gens ne sont pas reliés du tout)
# Si ton graphe s'appelle G
G_main = G.subgraph(max(nx.connected_components(G), key=len))
print(f"Calcul sur la composante principale : {len(G_main)} noeuds")

# 2. L'Astuce : Échantillonnage (Sampling)
# Calculer les chemins entre TOUS les nœuds est trop long (O(N^2)).
# On va prendre 100 nœuds au hasard et calculer leur distance vers tous les autres.
n_samples = 100
random_nodes = random.sample(list(G_main.nodes()), n_samples)

all_distances = []

print("Calcul des distances en cours...")
for source in random_nodes:
    # Calcule la distance de ce noeud vers tous les autres
    lengths = nx.single_source_shortest_path_length(G_main, source)
    # On garde toutes les longueurs (sauf 0, qui est la distance vers soi-même)
    all_distances.extend([d for d in lengths.values() if d > 0])

# 3. Affichage de la Loi Normale
plt.figure(figsize=(10, 6))

# Histogramme avec la courbe de densité (KDE) qui devrait ressembler à une cloche
sns.histplot(all_distances, discrete=True, stat="density", kde=True, color='mediumseagreen', alpha=0.6)

# On ajoute une vraie courbe normale théorique par-dessus pour comparer
mu, std = np.mean(all_distances), np.std(all_distances)
x = np.linspace(min(all_distances), max(all_distances), 100)
p = (1 / (std * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / std) ** 2)
plt.plot(x, p, 'r--', linewidth=2, label='Loi Normale Théorique')

plt.title(f'Distribution des distances (Degrees of Separation)\nMoyenne = {mu:.2f} sauts')
plt.xlabel('Distance (Nombre de sauts entre deux auteurs)')
plt.ylabel('Probabilité')
plt.legend()
plt.grid(axis='y', alpha=0.5)
plt.show()

import networkx as nx
import matplotlib.pyplot as plt
import random
import math

# ==========================================
# 1. PRÉPARATION (On garde environ 400 sommets)
# ==========================================
# On prend un sous-ensemble pour que les boucles for ne durent pas une éternité
N_TARGET = 800

if len(G) > N_TARGET:
    # On prend les noeuds les plus connectés
    degres = dict(G.degree)
    top_nodes = sorted(degres, key=degres.get, reverse=True)[:N_TARGET]
    sub_G = G.subgraph(top_nodes).copy()
else:
    sub_G = G.copy()

nodes = list(sub_G.nodes())

# ==========================================
# 2. INITIALISATION
# ==========================================
# Dictionnaire pour stocker les positions : { "Auteur": [x, y], ... }
positions = {node: [random.random(), random.random()] for node in nodes}

# Tes paramètres
b = 0.05        # Vitesse de déplacement
ITERATIONS = 50 # Nombre de fois qu'on applique la formule

print(f"Démarrage de la simulation 'non optimisée' sur {len(nodes)} noeuds...")

# ==========================================
# 3. LA FORMULE EXACTE (Double Boucle)
# ==========================================

for it in range(ITERATIONS):
    # On crée un dictionnaire pour stocker les nouvelles positions de ce tour
    nouvelles_positions = {}

    # Pour chaque point A
    for node_A in nodes:
        pos_A = positions[node_A]
        deplacement_x = 0
        deplacement_y = 0

        # On regarde l'interaction avec tous les points B
        for node_B in nodes:
            if node_A == node_B:
                continue # On ne calcule pas la force sur soi-même

            pos_B = positions[node_B]

            # Calcul du vecteur (PosB - PosA)
            vecteur_x = pos_B[0] - pos_A[0]
            vecteur_y = pos_B[1] - pos_A[1]

            # Calcul de la distance au carré ||PosB - PosA||^2
            dist_carre = vecteur_x**2 + vecteur_y**2

            # Petite sécurité pour ne pas diviser par 0 si deux points sont collés
            if dist_carre < 0.00001:
                dist_carre = 0.00001

            # exists_link(A,B) : 1 si lien, -1 sinon
            if sub_G.has_edge(node_A, node_B):
                signe = 1
            else:
                signe = -1

            # TA FORMULE : signe * b * (vecteur / dist²)
            # On factorise pour le calcul
            facteur = (signe * b) / dist_carre

            # On ajoute cette force au déplacement total de A
            deplacement_x += facteur * vecteur_x
            deplacement_y += facteur * vecteur_y

        # Fin de la boucle sur B : on calcule la nouvelle position de A
        nouveau_x = pos_A[0] + deplacement_x
        nouveau_y = pos_A[1] + deplacement_y

        nouvelles_positions[node_A] = [nouveau_x, nouveau_y]

    # Fin de la boucle sur A : on met à jour tout le monde pour le tour suivant
    positions = nouvelles_positions

print("Calcul terminé.")

# ==========================================
# 4. AFFICHAGE (Style Espace, sans liens, sans noms)
# ==========================================

# Récupération des coordonnées pour le plot
X = [positions[n][0] for n in nodes]
Y = [positions[n][1] for n in nodes]

# Récupération de la couleur (selon le degré)

plt.figure(figsize=(10, 10)) # Fond noir

plt.scatter(
    X, Y,
    s=30,           # Taille des points
    alpha=0.8,
    edgecolors='none'
)

plt.axis('off') # Pas d'axes
plt.title("Simulation Spatiale (Implémentation Naïve)", color='white')
plt.show()

import networkx as nx
import matplotlib.pyplot as plt
import random
import math

# ==========================================
# 1. PRÉPARATION
# ==========================================
N_TARGET = 800

if len(G) > N_TARGET:
    degres = dict(G.degree)
    top_nodes = sorted(degres, key=degres.get, reverse=True)[:N_TARGET]
    sub_G = G.subgraph(top_nodes).copy()
else:
    sub_G = G.copy()

nodes = list(sub_G.nodes())

# ==========================================
# 2. INITIALISATION
# ==========================================
positions = {node: [random.random(), random.random()] for node in nodes}

b = 0.05
ITERATIONS = 50

print(f"Démarrage de la simulation sur {len(nodes)} noeuds...")

# ==========================================
# 3. PHYSIQUE (Ta formule inchangée)
# ==========================================

for it in range(ITERATIONS):
    nouvelles_positions = {}

    for node_A in nodes:
        pos_A = positions[node_A]
        deplacement_x = 0
        deplacement_y = 0

        for node_B in nodes:
            if node_A == node_B: continue

            pos_B = positions[node_B]
            vecteur_x = pos_B[0] - pos_A[0]
            vecteur_y = pos_B[1] - pos_A[1]
            dist_carre = vecteur_x**2 + vecteur_y**2

            if dist_carre < 0.00001: dist_carre = 0.00001

            if sub_G.has_edge(node_A, node_B): signe = 1
            else: signe = -1

            facteur = (signe * b) / dist_carre
            deplacement_x += facteur * vecteur_x
            deplacement_y += facteur * vecteur_y

        nouveau_x = pos_A[0] + deplacement_x
        nouveau_y = pos_A[1] + deplacement_y
        nouvelles_positions[node_A] = [nouveau_x, nouveau_y]

    positions = nouvelles_positions

print("Calcul physique terminé.")

# ==========================================
# 4. CALCUL DE LA DENSITÉ BRUTE
# ==========================================
X = [positions[n][0] for n in nodes]
Y = [positions[n][1] for n in nodes]

largeur_graph = max(X) - min(X)
rayon_proximite = largeur_graph * 0.05
rayon_carre = rayon_proximite**2

densites_brutes = []

print("Calcul des densités...")
for i in range(len(nodes)):
    voisins = 0
    pos_A_x = X[i]
    pos_A_y = Y[i]
    for j in range(len(nodes)):
        dist_sq = (X[j] - pos_A_x)**2 + (Y[j] - pos_A_y)**2
        if dist_sq < rayon_carre:
            voisins += 1
    densites_brutes.append(voisins)

# ==========================================
# 5. APPLICATION DU SEUIL (La partie magique)
# ==========================================
print("Application du seuil de luminosité...")

max_densite = max(densites_brutes)

# === PARAMÈTRE À RÉGLER ICI ===
# On fixe le plafond à 20% du maximum réel.
# Cela veut dire que même les "petits" clusters seront considérés comme "très brillants"
RATIO_SEUIL = 0.20
seuil_coupure = max_densite * RATIO_SEUIL

densites_visuelles = []

for d in densites_brutes:
    # Si la densité dépasse le seuil, on la bloque au seuil
    if d > seuil_coupure:
        densites_visuelles.append(seuil_coupure)
    else:
        densites_visuelles.append(d)

# ==========================================
# 6. AFFICHAGE
# ==========================================
plt.figure(figsize=(10, 10), facecolor='black')

plt.scatter(
    X, Y,
    c=densites_visuelles,    # On utilise la densité "coupée"
    cmap='inferno',
    s=35,
    alpha=0.9,
    edgecolors='none'
)

plt.title(f"Visualisation avec seuil de saturation (Max={int(seuil_coupure)})", color='white')
plt.axis('off')
plt.show()

import matplotlib.pyplot as plt
import numpy as np
from sklearn.cluster import KMeans

# 1. PRÉPARATION DES DONNÉES
# On combine X et Y pour faire un tableau de points [[x1, y1], [x2, y2], ...]
# K-Means a besoin de cette forme
data_points = np.column_stack((X, Y))

# 2. CHOIX DU NOMBRE DE CLUSTERS (K)
# Combien de groupes vois-tu à l'œil nu ? Disons 5 pour l'exemple.
# Dans un vrai rapport, on utilise la méthode du "Coude" (Elbow) pour trouver ce chiffre.
K = 20

print(f"Lancement du K-Means pour trouver {K} clusters...")

# 3. L'ALGORITHME K-MEANS
kmeans = KMeans(n_clusters=K, random_state=42, n_init=10)
kmeans.fit(data_points)

# On récupère les résultats
labels = kmeans.labels_       # À quel groupe appartient chaque point (0, 1, 2...)
centers = kmeans.cluster_centers_ # Les coordonnées du centre de chaque cluster

# 4. AFFICHAGE
plt.figure(figsize=(10, 10), facecolor='black')

# On dessine les points, colorés selon leur cluster (c=labels)
plt.scatter(
    X, Y,
    c=labels,          # La couleur dépend du numéro du cluster
    cmap='Set1',       # Une palette avec des couleurs bien distinctes (Rouge, Bleu, Vert...)
    s=30,
    alpha=0.8,
    edgecolors='none'
)

# On dessine les CENTROÏDES (les croix blanches)
# C'est le "centre de gravité" de chaque groupe calculé par K-Means
plt.scatter(
    centers[:, 0], centers[:, 1],
    c='white',
    s=200,
    marker='X',        # Forme de croix
    edgecolors='black',
    linewidths=2,
    label='Centraux (Centroids)'
)

plt.title(f"Clustering K-Means (K={K}) appliqué sur ta simulation", color='white')
plt.axis('off')
plt.legend()
plt.show()